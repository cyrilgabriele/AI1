{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this project, you will create a classification model for dogs breeds, which should work on any photo and provide a classification outcome for it.\n",
        "The training data is in the folder Breeds classification/Dataset. You can find your own samples for testing the model outside of the provided data.\n",
        "\n",
        "The data loading and initial preprocessing is provided below. You are free to do further preprocessing if you think it might be useful.\n",
        "- Be careful if you are running pytorch on a machine with a gpu or a cpu, you might need to do some adjustments for that."
      ],
      "metadata": {
        "id": "ceE5T-ltACs5"
      },
      "id": "ceE5T-ltACs5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97461f11",
      "metadata": {
        "id": "97461f11"
      },
      "outputs": [],
      "source": [
        "#visualization\n",
        "import matplotlib.pyplot as plt\n",
        "#data manipulations\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#pytorch\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "from PIL import Image\n",
        "#dealing with images from Internet\n",
        "import requests\n",
        "from io import BytesIO\n",
        "# time tracking\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive files\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "id": "nRkyCGjUB5qu",
        "outputId": "40d958bc-5115-42a9-9953-3e71274eadcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nRkyCGjUB5qu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content\n",
            "gdrive\tsample_data\n",
            " Afghan\t\t     'Border Collie'\t Collie\t\t     Groenendael\t Pomeranian\n",
            "'African Wild Dog'    Borzoi\t\t Corgi\t\t    'Irish Spaniel'\t Poodle\n",
            " Airedale\t     'Boston Terrier'\t Coyote\t\t    'Irish Wolfhound'\t Pug\n",
            "'American Hairless'   Boxer\t\t Dalmation\t    'Japanese Spaniel'\t Rhodesian\n",
            "'American Spaniel'    Bulldog\t\t Dhole\t\t     Komondor\t\t Rottweiler\n",
            " Basenji\t     'Bull Mastiff'\t Dingo\t\t     Labradoodle\t'Saint Bernard'\n",
            " Basset\t\t     'Bull Terrier'\t Doberman\t     Labrador\t\t Schnauzer\n",
            " Beagle\t\t      Cairn\t\t'Elk Hound'\t     Lhasa\t\t'Scotch Terrier'\n",
            "'Bearded Collie'      Chihuahua\t\t'French Bulldog'     Malinois\t\t Shar_Pei\n",
            " Bermaise\t     'Chinese Crested'\t'German Sheperd'     Maltese\t\t'Shiba Inu'\n",
            "'Bichon Frise'\t      Chow\t\t'Golden Retriever'  'Mex Hairless'\t Shih-Tzu\n",
            " Blenheim\t      Clumber\t\t'Great Dane'\t     Newfoundland\t'Siberian Husky'\n",
            " Bloodhound\t      Cockapoo\t\t'Great Perenees'     Pekinese\t\t Vizsla\n",
            " Bluetick\t      Cocker\t\t Greyhound\t    'Pit Bull'\t\t Yorkie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75775e1b",
      "metadata": {
        "id": "75775e1b"
      },
      "source": [
        "Load the dataset after some standard transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0766ecbf",
      "metadata": {
        "id": "0766ecbf",
        "outputId": "b467c08d-bd5a-436c-b4be-f922bfa47747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-54b5dc5298a2>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mvalidset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/valid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mis_valid_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     ):\n\u001b[0;32m--> 309\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    310\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# is potentially overridden and thus could have a different logic.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The class_to_idx parameter cannot be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mmake_dataset\u001b[0;34m(directory, class_to_idx, extensions, is_valid_file)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Supported extensions are: {extensions if isinstance(extensions, str) else ', '.join(extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Found no valid file for the classes Afghan, African Wild Dog, Airedale, American Hairless, American Spaniel, Basenji, Basset, Beagle, Bearded Collie, Bermaise, Bichon Frise, Blenheim, Bloodhound, Bluetick, Border Collie, Borzoi, Boston Terrier, Boxer, Bull Mastiff, Bull Terrier, Bulldog, Cairn, Chihuahua, Chinese Crested, Chow, Clumber, Cockapoo, Cocker, Collie, Corgi, Coyote, Dalmation, Dhole, Dingo, Doberman, Elk Hound, French Bulldog, German Sheperd, Golden Retriever, Great Dane, Great Perenees, Greyhound, Groenendael, Irish Spaniel, Irish Wolfhound, Japanese Spaniel, Komondor, Labradoodle, Labrador, Lhasa, Malinois, Maltese, Mex Hairless, Newfoundland, Pekinese, Pit Bull, Pomeranian, Poodle, Pug, Rhodesian, Rottweiler, Saint Bernard, Schnauzer, Scotch Terrier, Shar_Pei, Shiba Inu, Shih-Tzu, Siberian Husky, Vizsla, Yorkie. Supported extensions are: .jpg, .jpeg, .png, .ppm, .bmp, .pgm, .tif, .tiff, .webp"
          ]
        }
      ],
      "source": [
        "\n",
        "# transforms for images\n",
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p = 0.5)\n",
        "])\n",
        "\n",
        "base_path = \"gdrive/MyDrive/Dataset_DOGS\"\n",
        "\n",
        "# datasets\n",
        "trainset = torchvision.datasets.ImageFolder(base_path + \"/test\", transform = transforms)\n",
        "validset = torchvision.datasets.ImageFolder(base_path + \"/valid\", transform = transforms)\n",
        "testset = torchvision.datasets.ImageFolder(base_path + \"/test\", transform = transforms)\n",
        "\n",
        "#batches\n",
        "batch_size = 128\n",
        "\n",
        "# loaders for data\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset , batch_size=batch_size , shuffle = True)\n",
        "validloader = torch.utils.data.DataLoader(validset , batch_size=batch_size , shuffle = True)\n",
        "testloader = torch.utils.data.DataLoader(testset  , batch_size=batch_size)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00ed5791",
      "metadata": {
        "id": "00ed5791"
      },
      "source": [
        "Visualize some images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "000acbdd",
      "metadata": {
        "id": "000acbdd"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloader))\n",
        "images, labels = images.numpy() , labels.numpy()\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (15,5))\n",
        "\n",
        "for i in range(int(batch_size/8)):\n",
        "    ax = fig.add_subplot(2 , int(batch_size/16) , i + 1 , xticks = [] , yticks = [])\n",
        "    ax.imshow(np.transpose(images[i] , (1,2,0)) , cmap = 'gray')\n",
        "    ax.set_title(trainset.classes[labels[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cacbae9",
      "metadata": {
        "id": "2cacbae9"
      },
      "outputs": [],
      "source": [
        "# Single batch\n",
        "print(\"number of train batches : \", len(trainloader))\n",
        "print(\"number of validation batches : \", len(validloader))\n",
        "print(\"Size of test batches : \", len(testloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abce2187",
      "metadata": {
        "id": "abce2187"
      },
      "outputs": [],
      "source": [
        "print(\"Classes : \", trainset.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6333fcfe",
      "metadata": {
        "id": "6333fcfe"
      },
      "source": [
        "From here on, you are free to run your classification model.\n",
        "\n",
        "You can train your own model, and/or use pretrained models.\n",
        "\n",
        "Can you achieve accuracy > 90% on all classes?\n",
        "\n",
        "The more detailed report you provide on the performance of the models, the more you can improve on your classification. Think which means of visualization and analysis you can provide. How do you measure the performance of your model? Which hyperparameters are critical to improve the performance?\n",
        "Can you apply your model to random images from the internet?\n",
        "\n",
        "You can try it on several images from different classes. What happens if you provide an image of other animal?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6709fa72",
      "metadata": {
        "id": "6709fa72"
      },
      "outputs": [],
      "source": [
        "#my_gpu = torch.cuda.is_available()\n",
        "#print(f'Train on gpu: {my_gpu}')\n",
        "device = torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5554fbbe",
      "metadata": {
        "scrolled": true,
        "id": "5554fbbe"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "model = torchvision.models.resnet18(pretrained = True)# Use ResNet 18\n",
        "#freeze model params\n",
        "for param in model.parameters():\n",
        "    param = param.requires_grad_(False)\n",
        "\n",
        "#new layer\n",
        "model.fc = nn.Sequential(\n",
        "                      nn.Linear(model.fc.in_features, 256),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Dropout(0.4),\n",
        "                      nn.Linear(256, len(trainset.classes)),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "\n",
        "print(\"The new layer is : \",model.fc)\n",
        "model = model.to(device) #Moving the model to GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc799e67",
      "metadata": {
        "id": "dc799e67"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters() , lr = lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf6a9b17",
      "metadata": {
        "id": "bf6a9b17"
      },
      "outputs": [],
      "source": [
        "class color_formats:\n",
        "    \"\"\"\n",
        "    Simple color formating:\n",
        "    Variables:\n",
        "        >OKCYAN - cyan printing.\n",
        "        >Bold - bold printing.\n",
        "        >UNDERLINE - underline printing.\n",
        "    \"\"\"\n",
        "    OKCYAN = '\\033[96m'\n",
        "    ENDC = '\\033[0m'\n",
        "    BOLD = '\\033[1m'\n",
        "    UNDERLINE = '\\033[4m'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1759b879",
      "metadata": {
        "id": "1759b879",
        "outputId": "d7604e36-2593-4da6-e6b5-d1cf90506e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5d64cd0c91b2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m def train_loop(model,\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "device = torch.device('cpu')\n",
        "model = model.to(device)\n",
        "print(device)\n",
        "\n",
        "def train_loop(model,\n",
        "          criterion,\n",
        "          optimizer,\n",
        "          train_loader,\n",
        "          valid_loader,\n",
        "          save_model_name,\n",
        "          max_epochs_stop=1, #3\n",
        "          num_epochs=3,      #20\n",
        "          num_epochs_report=2):\n",
        "    \"\"\"Train a neural network Model\n",
        "    Args\n",
        "    --------\n",
        "        >model (Pytorch nn model): The neural network for the training process.\n",
        "        >criterion (Pytorch loss function): Initialize the loss function.\n",
        "        >optimizer (Pytorch optimizer): Use an optimizer to compute gradients to update the weights.\n",
        "        >train_loader (Pytorch dataloader): training dataloader to iterate through.\n",
        "        >valid_loader (Pytorch dataloader): validation dataloader used for early stopping.\n",
        "        >save_model_name (str): file path to save the model state dict, file name ends with 'pt.'.\n",
        "        >max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping.\n",
        "        >num_epochs (int): maximum number of training epochs if the early stopping is not activated.\n",
        "        >num_epochs_report (int): frequency of epochs to print training reports.\n",
        "\n",
        "    outputs\n",
        "    --------\n",
        "        >model (PyTorch model): Trained neural networks with best weights.\n",
        "        >history (DataFrame): History of train and validation loss and accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Early stopping intialization\n",
        "    epochs_no_improve = 0\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    valid_max_acc = 0\n",
        "    history = []\n",
        "\n",
        "    # Number trained epochs  (while using loaded in model weights)\n",
        "    try:\n",
        "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
        "    except:\n",
        "        model.epochs = 0\n",
        "        print(f'{color_formats.BOLD + color_formats.UNDERLINE}Training activated:{color_formats.ENDC}\\n')\n",
        "\n",
        "    overall_start = timer()\n",
        "\n",
        "    # Start of loop\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        # Track of training and validation loss for each epoch\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        train_acc = 0\n",
        "        valid_acc = 0\n",
        "\n",
        "        # Set model to train\n",
        "        model.train()\n",
        "\n",
        "        #start timer\n",
        "        start = timer()\n",
        "\n",
        "        # Training loop\n",
        "        for ii, (data, target) in enumerate(train_loader):\n",
        "            # Put the data in the gpu\n",
        "            #if my_gpu:\n",
        "            #    data, target = data.to(device), target.to(device)\n",
        "            #if cpu:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # Remove past gradients\n",
        "            optimizer.zero_grad()\n",
        "            # Predicted outputs as log probabilities\n",
        "            output = model(data)\n",
        "\n",
        "            # Loss and backpropagation of gradients\n",
        "            loss = criterion(output, target.long())\n",
        "            loss.backward()\n",
        "\n",
        "            # Update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # Track train loss by multiplying average loss by number of examples in batch\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "\n",
        "            # Calculate accuracy by finding max log probability\n",
        "            _, pred = torch.max(output, dim=1)\n",
        "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "            # Need to convert correct tensor from int to float to average\n",
        "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
        "            # Multiply average accuracy times the number of examples in batch\n",
        "            train_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "            # Training progress tracker\n",
        "            print(\n",
        "                f'Epoch: {epoch+1}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
        "                end='\\r')\n",
        "\n",
        "\n",
        "        # Start validation after training loops ends.\n",
        "        else:\n",
        "            model.epochs += 1\n",
        "\n",
        "            # Deactivate the gradient tracking.\n",
        "            with torch.no_grad():\n",
        "                # Set to evaluation mode\n",
        "                model.eval()\n",
        "\n",
        "                # Validation loop\n",
        "                for data, target in valid_loader:\n",
        "                    # Put the data in the gpu\n",
        "                    #if my_gpu:\n",
        "                        #data, target = data.to(device), target.to(device)\n",
        "                    data, target = data.to(device), target.to(device)\n",
        "                    # Predicted outputs as log probabilities\n",
        "                    output = model(data)\n",
        "\n",
        "                    # Validation loss\n",
        "                    loss = criterion(output, target.long())\n",
        "                    # Multiply average loss times the number of examples in batch\n",
        "                    valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "                    # Calculate accuracy of validation set\n",
        "                    _, pred = torch.max(output, dim=1)\n",
        "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "                    accuracy = torch.mean(\n",
        "                        correct_tensor.type(torch.FloatTensor))\n",
        "                    # Multiply average accuracy times the number of examples\n",
        "                    valid_acc += accuracy.item() * data.size(0)\n",
        "\n",
        "                # Calculate average losses\n",
        "                train_loss = train_loss / len(train_loader.dataset)\n",
        "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
        "\n",
        "                # Calculate average accuracy\n",
        "                train_acc = train_acc / len(train_loader.dataset)\n",
        "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
        "\n",
        "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
        "\n",
        "                # Print training and validation results for the num_epochs_report that was set\n",
        "                if (epoch + 1) % num_epochs_report == 0:\n",
        "                    print(\n",
        "                        f'\\n\\nEpoch: {color_formats.BOLD}{epoch+1}{color_formats.ENDC} \\tTraining Loss: {color_formats.BOLD}{train_loss:.4f}{color_formats.ENDC} \\tValidation Loss: {color_formats.BOLD}{valid_loss:.4f}{color_formats.ENDC}'\n",
        "                    )\n",
        "                    print(\n",
        "                        f'\\t\\tTraining Accuracy: {color_formats.BOLD}{100 * train_acc:.2f}%{color_formats.ENDC}\\t Validation Accuracy: {color_formats.BOLD}{100 * valid_acc:.2f}%{color_formats.ENDC}\\n'\n",
        "                    )\n",
        "\n",
        "                # Save the model if validation loss decreases\n",
        "                if valid_loss < valid_loss_min:\n",
        "                    # Save model\n",
        "                    torch.save(model.state_dict(), save_model_name)\n",
        "                    # Track improvement\n",
        "                    epochs_no_improve = 0\n",
        "                    valid_loss_min = valid_loss\n",
        "                    valid_best_acc = valid_acc\n",
        "                    best_epoch = epoch + 1\n",
        "\n",
        "                # Otherwise count all consecutive epochs with no improvement.\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "                    # Trigger early stopping\n",
        "                    if epochs_no_improve >= max_epochs_stop:\n",
        "                        print(\n",
        "                            f'\\n\\n{color_formats.OKCYAN}Early stopping activated!{color_formats.ENDC}\\nthe validation loss has not improved for {max_epochs_stop} epochs.\\n\\n{color_formats.BOLD + color_formats.UNDERLINE}End of training report:{color_formats.ENDC}\\n\\n\\t-Total epochs: {epoch+1} \\n\\t-Best epoch: {color_formats.BOLD}{best_epoch}{color_formats.ENDC} \\n\\t-loss: {color_formats.BOLD}{valid_loss_min:.2f}{color_formats.ENDC} \\n\\t-accuracy: {color_formats.BOLD}{100 * valid_best_acc:.2f}%\\n{color_formats.ENDC}'\n",
        "                        )\n",
        "                        total_time = timer() - overall_start\n",
        "                        print(\n",
        "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
        "                        )\n",
        "\n",
        "                        # Load the best state dict\n",
        "                        model.load_state_dict(torch.load(save_model_name))\n",
        "                        # Attach the optimizer\n",
        "                        model.optimizer = optimizer\n",
        "\n",
        "                        # History update\n",
        "                        history = pd.DataFrame(\n",
        "                            history,\n",
        "                            columns=[\n",
        "                                'train_loss', 'valid_loss', 'train_acc',\n",
        "                                'valid_acc'\n",
        "                            ])\n",
        "                        return model, history\n",
        "\n",
        "\n",
        "    # Record overall time and print out Report\n",
        "    total_time = timer() - overall_start\n",
        "    print(\n",
        "        f'\\nBest epoch is epoch #{best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
        "    )\n",
        "    print(\n",
        "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch):.2f} seconds per epoch.'\n",
        "    )\n",
        "    # History update\n",
        "    history = pd.DataFrame(\n",
        "        history,\n",
        "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7c89817",
      "metadata": {
        "id": "b7c89817"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "print(\"Device\", device)\n",
        "model, history = train_loop(\n",
        "    model,\n",
        "    criterion,\n",
        "    optimizer,\n",
        "    trainloader,\n",
        "    validloader,\n",
        "    save_model_name=\"./model2.pt\",\n",
        "    max_epochs_stop=2,\n",
        "    num_epochs=3,\n",
        "    num_epochs_report=3,)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d97a724",
      "metadata": {
        "id": "3d97a724"
      },
      "outputs": [],
      "source": [
        "#models logs in detail over time of training.\n",
        "\n",
        "history.index = [idx for idx in range(1, history.shape[0]+1)] #from first epoch\n",
        "fig, axs = plt.subplots(1, 2, figsize = (10,5))\n",
        "fig.suptitle('History Log',  size = 20)\n",
        "#ethnicity model log\n",
        "\n",
        "axs[0].plot(history[\"train_loss\"], label = \"train\")\n",
        "axs[0].plot(history[\"valid_loss\"], label = \"validation\")\n",
        "axs[0].set_xlabel(\"epochs\")\n",
        "axs[0].set_ylabel(\"loss\")\n",
        "axs[0].legend()\n",
        "axs[0].set_title('Dog breed Classifier model loss')\n",
        "\n",
        "axs[1].plot(history[\"train_acc\"], label = \"train\")\n",
        "axs[1].plot(history[\"valid_acc\"], label = \"validation\")\n",
        "axs[1].set_xlabel(\"epochs\")\n",
        "axs[1].set_ylabel(\"accuracy\")\n",
        "axs[1].legend()\n",
        "axs[1].set_title('Dog breed Classifier accuracy')\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9333ce15",
      "metadata": {
        "id": "9333ce15"
      },
      "outputs": [],
      "source": [
        "def Accuracy_report(loader = None, model = None, n_classes = None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "    >loader (pytorch dataloader): the data for accuracy testing.\n",
        "    >model (pytorch model) : the neural network.\n",
        "    >n_classes (int): the number of classes.\n",
        "\n",
        "    Output:\n",
        "    > class_acc (dict) : accuracy per classes. non existant taregts in the test set are set to nan value.\n",
        "    > acc (float): overall accuracy.\n",
        "    \"\"\"\n",
        "    my_classes = []\n",
        "\n",
        "    classes = [n_class for n_class in range(n_classes)]\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            inputs, targets = data\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "\n",
        "            # collect the correct predictions for each class\n",
        "            for target, prediction in zip(targets, predictions):\n",
        "                if target == prediction:\n",
        "                    correct_pred[classes[target]] += 1\n",
        "                total_pred[classes[target]] += 1\n",
        "\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        try:\n",
        "            accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "\n",
        "            my_classes.append(accuracy)\n",
        "        except ZeroDivisionError:\n",
        "            my_classes.append(np.nan)\n",
        "            continue\n",
        "\n",
        "    acc =  round(100 * float(sum(correct_pred.values())/sum(total_pred.values())),2)\n",
        "    class_acc = dict(zip(classes,[round(mc,2) for mc in my_classes]))\n",
        "    return class_acc, acc\n",
        "\n",
        "def test_report(class_acc,acc):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        > my_classes (dict) : accuracy per classes. non existant taregts in the test set are set to nan value.\n",
        "        > acc (float): overall accuracy.\n",
        "\n",
        "    Output:\n",
        "        >report of test performance.\n",
        "    \"\"\"\n",
        "    print(f\"{color_formats.BOLD + color_formats.UNDERLINE}Test Accuracy Report{color_formats.ENDC}\")\n",
        "    for key,value in class_acc.items():\n",
        "        print(f\"Class {trainset.classes[key]} has achived {color_formats.BOLD}{value}%{color_formats.ENDC} accuracy\\n\")\n",
        "    print(f\"Overall accuracy: {color_formats.BOLD}{acc}%{color_formats.ENDC}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ba2a14c",
      "metadata": {
        "id": "1ba2a14c"
      },
      "outputs": [],
      "source": [
        "m1_test_class_acc, m1_test_acc = Accuracy_report(loader = testloader,model = model, n_classes = 70)\n",
        "test_report(m1_test_class_acc,m1_test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae0b9d5",
      "metadata": {
        "id": "5ae0b9d5"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(testloader)\n",
        "\n",
        "\n",
        "#images, labels = dataiter.next()\n",
        "images, labels = next(iter(testloader))\n",
        "# get predictions\n",
        "preds = np.squeeze(model(images).data.max(1, keepdim=True)[1].cpu().numpy())\n",
        "images = images.cpu().numpy()\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(int(batch_size/8)):\n",
        "    ax = fig.add_subplot(2, int(batch_size/16), idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx].transpose(1,2,0)), cmap='gray')\n",
        "    ax.set_title(\"{} ({})\".format(trainset.classes[preds[idx]], trainset.classes[labels[idx]]),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94aa25ac",
      "metadata": {
        "id": "94aa25ac"
      },
      "outputs": [],
      "source": [
        "url = \"https://i.pinimg.com/474x/95/99/07/959907c103998d280743ea0ea120121b.jpg\"\n",
        "#url = \"https://i.guim.co.uk/img/media/26392d05302e02f7bf4eb143bb84c8097d09144b/446_167_3683_2210/master/3683.jpg?width=1200&quality=85&auto=format&fit=max&s=a52bbe202f57ac0f5ff7f47166906403\"\n",
        "response = requests.get(url)\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1678fa7",
      "metadata": {
        "id": "d1678fa7"
      },
      "outputs": [],
      "source": [
        "transforms = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.Resize(224),\n",
        "    torchvision.transforms.Resize(256),\n",
        "    torchvision.transforms.CenterCrop(224),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.RandomHorizontalFlip(p = 0.5)\n",
        "])\n",
        "\n",
        "\n",
        "def predictor(img, n=5):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        >img - the image to predict.\n",
        "        >n - number of top probabilities.\n",
        "\n",
        "    Outputs:\n",
        "        >pred - the top prediction.\n",
        "        > top preds - top n predictions.\n",
        "    \"\"\"\n",
        "    #transform the image\n",
        "    img = transforms(img)\n",
        "    # get the class predicted\n",
        "    pred = int(np.squeeze(model(img.unsqueeze(0)).data.max(1, keepdim=True)[1].cpu().numpy()))\n",
        "    # the number is also the index for the class label\n",
        "    pred = trainset.classes[pred]\n",
        "    # get model log probabilities\n",
        "    preds = torch.from_numpy(np.squeeze(model(img.unsqueeze(0)).data.cpu().numpy()))\n",
        "    # convert to prediction probabilities of the top n predictions\n",
        "    top_preds = torch.topk(torch.exp(preds),n)\n",
        "    #display at an orgenized fasion\n",
        "    top_preds = dict(zip([trainset.classes[i] for i in top_preds.indices],[f\"{round(float(i)*100,2)}%\" for i in top_preds.values]))\n",
        "    return pred, top_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb24396b",
      "metadata": {
        "id": "bb24396b"
      },
      "outputs": [],
      "source": [
        "my_prediction, top_predictions = predictor(img, n=5)\n",
        "#print(\"Is CUDA enabled?\",torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85d6d738",
      "metadata": {
        "id": "85d6d738"
      },
      "outputs": [],
      "source": [
        "my_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2e87b77",
      "metadata": {
        "id": "a2e87b77"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7e9743",
      "metadata": {
        "id": "9d7e9743"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}